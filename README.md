# About

Quick experiments with multi-armed bandit algorithms, particularly over short time horizions.  (Short time horizons are more relevant to human agents, though many papers/notes study algorithmic performance over very long time horizons.)  

Also reproduces the finding in "Multi-Armed Bandit Algorithms and Empirical
Evaluation" that the epsilon-greedy algorithm can be surprisingly competitive with much more sophisticated algorithms.